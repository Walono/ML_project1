{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Useful starting lines\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from Methods.costs import * \n",
    "from Methods.least_squares import * \n",
    "from Methods.ridge import *\n",
    "from Methods.cross_validation import *\n",
    "from Methods.split_data import *\n",
    "from Methods.scaling_standardization import *\n",
    "from Methods.build_polynomial import *\n",
    "from Methods.clearDataset import *\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the training data into feature matrix, class labels, and event ids:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from Methods.proj1_helpers import *\n",
    "DATA_TRAIN_PATH = 'csv/train.csv'\n",
    "y, tX, ids = load_csv_data(DATA_TRAIN_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate predictions and save ouput in csv format for submission:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "DATA_TEST_PATH = 'csv/test.csv' # TODO: download train data and supply path here \n",
    "_, tX_test, ids_test = load_csv_data(DATA_TEST_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data exploratory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tX, tX_test = averageData(tX, tX_test)\n",
    "tX, tX_test = data_scaling(tX.T, tX_test.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Features transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#y, x, tX, method,  tX_test, x_test, **kwargs\n",
    "for i in range(0, 30): \n",
    "    tX, tX_test = add_feature(y, tX[i], tX, log_def, tX_test, tX_test[i])\n",
    "    tX, tX_test = add_feature(y, tX[i], tX, multiply, tX_test, tX_test[i], degree=2)\n",
    "    tX, tX_test = add_feature(y, tX[i], tX, multiply, tX_test, tX_test[i], degree=3)\n",
    "    tX, tX_test = add_feature(y, tX[i], tX, sqrt_def, tX_test, tX_test[i])\n",
    "    #tX, tX_test = add_feature(y, tX[i], tX, cos_def, tX_test, tX_test[i])\n",
    "    tX, tX_test = add_feature(y, tX[i], tX, multiply, tX_test, tX_test[i], degree=4)\n",
    "    tX, tX_test = add_feature(y, tX[i], tX, multiply, tX_test, tX_test[i], degree=5)\n",
    "    tX, tX_test = add_feature(y, tX[i], tX, multiply, tX_test, tX_test[i], degree=6)\n",
    "    tX, tX_test = add_feature(y, tX[i], tX, multiply, tX_test, tX_test[i], degree=7)\n",
    "    #tX, tX_test = add_feature(y, tX[i], tX, multiply, tX_test, tX_test[i], degree=8)   \n",
    "\n",
    "tX = tX.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8092\n",
      "1\n",
      "[0.88074614831844589]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "seed = 1\n",
    "k_fold = 10\n",
    "\n",
    "# split data in k fold\n",
    "k_indices = build_k_indices(y, k_fold, seed)\n",
    "\n",
    "# define lists to store the loss of training data and test data\n",
    "rmse_tr = []\n",
    "rmse_te = []\n",
    "k_list = list(range(k_fold))\n",
    "#k=7\n",
    "tot_loss_tr = 0\n",
    "tot_loss_te = 0\n",
    "best_accuracy = 0\n",
    "best_k = 0\n",
    "weights = np.array([])\n",
    "for k in k_list:\n",
    "    loss_tr, loss_te, accuracy_least, w = cross_validation(y, tX, k_indices, k, least_squares)\n",
    "    tot_loss_tr += loss_tr\n",
    "    tot_loss_te += loss_te\n",
    "    if accuracy_least > best_accuracy:\n",
    "        best_accuracy = accuracy_least\n",
    "        best_k = k\n",
    "        weights = w\n",
    "rmse_tr.append(np.sqrt(2/k_fold * tot_loss_tr))\n",
    "rmse_te.append(np.sqrt(2/k_fold * tot_loss_te))\n",
    "print(best_accuracy)\n",
    "print(best_k)\n",
    "print(rmse_tr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ridge regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "seed = 1\n",
    "k_fold = 4\n",
    "\n",
    "# split data in k fold\n",
    "k_indices = build_k_indices(y, k_fold, seed)\n",
    "\n",
    "# define lists to store the loss of training data and test data\n",
    "rmse_tr = []\n",
    "rmse_te = []\n",
    "k_list = list(range(k_fold))\n",
    "#k=7\n",
    "lambdas = np.logspace(-10, -2, 20)\n",
    "tot_loss_tr = 0\n",
    "tot_loss_te = 0\n",
    "best_accuracy = 0\n",
    "best_k = 0\n",
    "best_l = 0\n",
    "weights = np.array([])\n",
    "for l in lambdas:\n",
    "    for k in k_list:\n",
    "        loss_tr, loss_te, accuracy_least, w = cross_validation(y, tX, k_indices, k, ridge_regression, lambda_=l)\n",
    "        tot_loss_tr += loss_tr\n",
    "        tot_loss_te += loss_te\n",
    "        if accuracy_least > best_accuracy:\n",
    "            best_accuracy = accuracy_least\n",
    "            best_k = k\n",
    "            weights = w\n",
    "            best_l = l\n",
    "    rmse_tr.append(np.sqrt(2/k_fold * tot_loss_tr))\n",
    "    rmse_te.append(np.sqrt(2/k_fold * tot_loss_te))\n",
    "    \n",
    "cross_validation_visualization(lambdas, rmse_tr, rmse_te)\n",
    "print(best_accuracy)\n",
    "print(best_k)\n",
    "print(best_l)\n",
    "print(rmse_tr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Logistic regression on half of train data\n",
    "y_binary = np.copy(y)\n",
    "y_binary[y_binary == -1] = 0\n",
    "w_log = logistic_regression_gradient_descent_demo(y_binary[:125000], tX[:125000], batch_size=3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vect = sigmoid(np.dot(tX[-125000:], w_log))\n",
    "vect[vect >= 0.5] = 1\n",
    "vect[vect < 0.5] = -1\n",
    "e_log = y[-125000:] - vect[:,0]\n",
    "rmse_log = np.sqrt(2*calculate_mse(e_log))\n",
    "tot = 0\n",
    "for i in range(125000, 250000):\n",
    "    if y[i] == vect[i-125000]:\n",
    "        tot += 1\n",
    "print(\"Accuracy: \", tot/125000, \"RMSE: \", rmse_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Prepare output if logistic regression\n",
    "pred_log = sigmoid(np.dot(tX_test.T, w_log))\n",
    "pred_log = pred_log[:,0]\n",
    "pred_log[pred_log >= 0.5] = 1\n",
    "pred_log[pred_log < 0.5] = -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Penalized logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Biais variance decomposition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "OUTPUT_PATH = 'csv/sample-submission.csv' # TODO: fill in desired name of output file for submission\n",
    "y_pred = predict_labels(weights, tX_test.T)\n",
    "create_csv_submission(ids_test, y_pred, OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#create_csv_submission(ids_test, pred_log, OUTPUT_PATH)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
