{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Useful starting lines\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from Methods.costs import * \n",
    "from Methods.least_squares import * \n",
    "from Methods.ridge import *\n",
    "from Methods.cross_validation import *\n",
    "from Methods.split_data import *\n",
    "from Methods.scaling_standardization import *\n",
    "from Methods.build_polynomial import *\n",
    "from Methods.clearDataset import *\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the training data into feature matrix, class labels, and event ids:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from Methods.proj1_helpers import *\n",
    "DATA_TRAIN_PATH = 'csv/train.csv'\n",
    "y, tX, ids = load_csv_data(DATA_TRAIN_PATH)\n",
    "tX_tra = tX.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do your thing crazy machine learning thing here :) ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Raw Data Analysis "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualisation of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Boxplot of the Raw Data\n",
    "#boxplot(tX, -2000, 6000, 'boxplot_original')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Â Feature Deletion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#PERCENT_FACTOR = 0.5\n",
    "#dele_tX_temp = deleteNoneWantedData(tX, PERCENT_FACTOR)\n",
    "#dele_tX = deleteUnwantedLine(dele_tX_temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Replace Undefined variables by mean of all the other variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tX = np.array(averageData(tX))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data scaling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tX = data_scaling(tX.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Boxplot of the scale data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#boxplot(tX, -0.5, 1.5, 'boxplot_scaled')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#tX = data_standardization(tX.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Boxplot of the Standardized data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#boxplot(std_tX, -7, 7, 'boxplot_standardized')\n",
    "acc_arr = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/JulieDjeffal/Documents/EPFL/pattern/2016/ML_project1/projects/project1/scripts/Methods/build_polynomial.py:32: RuntimeWarning: divide by zero encountered in log\n",
      "  new = np.array([np.log(x)])\n",
      "/Users/JulieDjeffal/anaconda/lib/python3.5/site-packages/numpy/lib/function_base.py:964: RuntimeWarning: invalid value encountered in multiply\n",
      "  scl = np.multiply(avg, 0) + scl\n",
      "/Users/JulieDjeffal/anaconda/lib/python3.5/site-packages/numpy/lib/function_base.py:2490: RuntimeWarning: invalid value encountered in subtract\n",
      "  X -= avg[:, None]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.95808836  0.13548839 -0.69782112 ...,  0.20715263 -0.80155664\n",
      " -0.86394769]\n",
      "[-1.  1. -1. ...,  1. -1. -1.]\n",
      "[-1. -1. -1. ...,  1. -1. -1.]\n",
      "0.80712\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, 30):\n",
    "    tX = add_feature(y, tX.T[i], tX, log_def)\n",
    "    tX = add_feature(y, tX.T[i], tX, multiply, degree=2)\n",
    "    tX = add_feature(y, tX.T[i], tX, multiply, degree=3)\n",
    "    tX = add_feature(y, tX.T[i], tX, sqrt_def)\n",
    "\n",
    "seed = 1\n",
    "k_fold = 10\n",
    "\n",
    "# split data in k fold\n",
    "k_indices = build_k_indices(y, k_fold, seed)\n",
    "\n",
    "# define lists to store the loss of training data and test data\n",
    "rmse_tr = []\n",
    "rmse_te = []\n",
    "#k_list = list(range(k_fold))\n",
    "k=7\n",
    "tot_loss_tr = 0\n",
    "tot_loss_te = 0\n",
    "best_accuracy = 0\n",
    "best_k = 0\n",
    "weights = np.array([])\n",
    "#for k in k_list:\n",
    "loss_tr, loss_te, accuracy_least, w = cross_validation(y, tX, k_indices, k, least_squares)\n",
    "tot_loss_tr += loss_tr\n",
    "tot_loss_te += loss_te\n",
    "if accuracy_least > best_accuracy:\n",
    "    best_accuracy = accuracy_least\n",
    "    best_k = k\n",
    "    weights = w\n",
    "rmse_tr.append(np.sqrt(2/k_fold * tot_loss_tr))\n",
    "rmse_te.append(np.sqrt(2/k_fold * tot_loss_te))\n",
    "print(best_accuracy)\n",
    "print(best_k)\n",
    "#print(weights)\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(250000, 100)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Big Magic Method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Least Squares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "seed = 1\n",
    "k_fold = 10\n",
    "\n",
    "# split data in k fold\n",
    "k_indices = build_k_indices(y, k_fold, seed)\n",
    "\n",
    "# define lists to store the loss of training data and test data\n",
    "rmse_tr = []\n",
    "rmse_te = []\n",
    "k_list = list(range(k_fold))\n",
    "tot_loss_tr = 0\n",
    "tot_loss_te = 0\n",
    "for k in k_list:\n",
    "    loss_tr, loss_te, accuracy_least = cross_validation(y, tX, k_indices, k, least_squares)\n",
    "    tot_loss_tr += loss_tr\n",
    "    tot_loss_te += loss_te\n",
    "rmse_tr.append(np.sqrt(2/k_fold * tot_loss_tr))\n",
    "rmse_te.append(np.sqrt(2/k_fold * tot_loss_te))\n",
    "\n",
    "accuracy_least"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "seed = 1\n",
    "k_fold = 10\n",
    "lambdas = np.logspace(-5, 1, 20)\n",
    "\n",
    "# split data in k fold\n",
    "k_indices = build_k_indices(y, k_fold, seed)\n",
    "\n",
    "# define lists to store the loss of training data and test data\n",
    "rmse_tr = []\n",
    "rmse_te = []\n",
    "best_accuracy = 0\n",
    "best_lamb = 0\n",
    "best_k = 0\n",
    "k_list = list(range(k_fold))\n",
    "for lamb in lambdas:\n",
    "    tot_loss_tr = 0\n",
    "    tot_loss_te = 0\n",
    "    for k in k_list:\n",
    "        loss_tr, loss_te, accuracy_ridge = cross_validation(y, tX, k_indices, k, ridge_regression, lamb = lamb)\n",
    "        if accuracy_ridge > best_accuracy:\n",
    "            best_accuracy = accuracy_ridge\n",
    "            best_lamb = lamb\n",
    "            best_k = k\n",
    "        tot_loss_tr += loss_tr\n",
    "        tot_loss_te += loss_te\n",
    "    rmse_tr.append(np.sqrt(2/k_fold * tot_loss_tr))\n",
    "    rmse_te.append(np.sqrt(2/k_fold * tot_loss_te))\n",
    "#plt.boxplot(rmse_te)\n",
    "#plt.show()\n",
    "#print(rmse_te)\n",
    "#cross_validation_visualization(lambdas, rmse_tr, rmse_te)\n",
    "print(best_accuracy)\n",
    "print(best_k)\n",
    "print(best_lamb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Bias-Variance decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(tX.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binary Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Use predict_labels de project helpers (fait la multiplication entre tX et les w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate predictions and save ouput in csv format for submission:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "DATA_TEST_PATH = 'csv/test.csv' # TODO: download train data and supply path here \n",
    "_, tX_test, ids_test = load_csv_data(DATA_TEST_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-999.   ,   79.589,   23.916, ..., -999.   , -999.   ,    0.   ],\n",
       "       [ 106.398,   67.49 ,   87.949, ..., -999.   , -999.   ,   47.575],\n",
       "       [ 117.794,   56.226,   96.358, ..., -999.   , -999.   ,    0.   ],\n",
       "       ..., \n",
       "       [ 108.497,    9.837,   65.149, ..., -999.   , -999.   ,    0.   ],\n",
       "       [  96.711,   20.006,   66.942, ..., -999.   , -999.   ,   30.863],\n",
       "       [  92.373,   80.109,   77.619, ..., -999.   , -999.   ,    0.   ]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tX_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/JulieDjeffal/Documents/EPFL/pattern/2016/ML_project1/projects/project1/scripts/Methods/clearDataset.py:66: FutureWarning: comparison to `None` will result in an elementwise object comparison in the future.\n",
      "  if tX_test != None:\n",
      "/Users/JulieDjeffal/Documents/EPFL/pattern/2016/ML_project1/projects/project1/scripts/Methods/scaling_standardization.py:9: FutureWarning: comparison to `None` will result in an elementwise object comparison in the future.\n",
      "  if x_te != None:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(568308, 30)\n"
     ]
    }
   ],
   "source": [
    "tX_test = averageData(tX, tX_test)\n",
    "tX_test = data_scaling(tX, tX_test)\n",
    "#data_scaling(tX_test.T)\n",
    "\n",
    "print(tX_test.shape)\n",
    "\n",
    "\n",
    "#for i in range(0, 30):    \n",
    "#    tX_test = add_feature_test(y, tX.T[i],tX_test.T[i], tX_test, log_def)\n",
    "#    tX_test = add_feature_test(y, tX.T[i],tX_test.T[i], tX_test, multiply, degree=2)\n",
    "#    tX_test = add_feature_test(y, tX.T[i],tX_test.T[i], tX_test, multiply, degree=3)\n",
    "#    tX_test = add_feature_test(y, tX.T[i],tX_test.T[i], tX_test, sqrt_def)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31, 568308)\n",
      "(97, 568308)\n"
     ]
    }
   ],
   "source": [
    "#log: x: 0, 1, 2, 3,7,8,9,10,13,14,16,17,18,19,21,22,24,25,26,27,28,29\n",
    "tmp = np.vstack((tX_test.T, log_def(tX_test.T[0])[0]))\n",
    "print(tmp.shape)\n",
    "tmp = np.vstack((tmp, log_def(tX_test.T[1])[0]))\n",
    "tmp = np.vstack((tmp, log_def(tX_test.T[2])[0]))\n",
    "tmp = np.vstack((tmp, log_def(tX_test.T[3])[0]))\n",
    "tmp = np.vstack((tmp, log_def(tX_test.T[7])[0]))\n",
    "tmp = np.vstack((tmp, log_def(tX_test.T[8])[0]))\n",
    "tmp = np.vstack((tmp, log_def(tX_test.T[9])[0]))\n",
    "tmp = np.vstack((tmp, log_def(tX_test.T[10])[0]))\n",
    "tmp = np.vstack((tmp, log_def(tX_test.T[13])[0]))\n",
    "tmp = np.vstack((tmp, log_def(tX_test.T[14])[0]))\n",
    "tmp = np.vstack((tmp, log_def(tX_test.T[16])[0]))\n",
    "tmp = np.vstack((tmp, log_def(tX_test.T[17])[0]))\n",
    "tmp = np.vstack((tmp, log_def(tX_test.T[18])[0]))\n",
    "tmp = np.vstack((tmp, log_def(tX_test.T[19])[0]))\n",
    "tmp = np.vstack((tmp, log_def(tX_test.T[21])[0]))\n",
    "tmp = np.vstack((tmp, log_def(tX_test.T[22])[0]))\n",
    "tmp = np.vstack((tmp, log_def(tX_test.T[24])[0]))\n",
    "tmp = np.vstack((tmp, log_def(tX_test.T[25])[0]))\n",
    "tmp = np.vstack((tmp, log_def(tX_test.T[26])[0]))\n",
    "tmp = np.vstack((tmp, log_def(tX_test.T[27])[0]))\n",
    "tmp = np.vstack((tmp, log_def(tX_test.T[28])[0]))\n",
    "tmp = np.vstack((tmp, log_def(tX_test.T[29])[0]))\n",
    "#carrÃ©: x: 0,2,4,11,12,14,15,17,19,24,25,27\n",
    "tmp = np.vstack((tmp, multiply(tX_test.T[0], degree=2)[0]))\n",
    "tmp = np.vstack((tmp, multiply(tX_test.T[2], degree=2)[0]))\n",
    "tmp = np.vstack((tmp, multiply(tX_test.T[4], degree=2)[0]))\n",
    "tmp = np.vstack((tmp, multiply(tX_test.T[11], degree=2)[0]))\n",
    "tmp = np.vstack((tmp, multiply(tX_test.T[12], degree=2)[0]))\n",
    "tmp = np.vstack((tmp, multiply(tX_test.T[14], degree=2)[0]))\n",
    "tmp = np.vstack((tmp, multiply(tX_test.T[15], degree=2)[0]))\n",
    "tmp = np.vstack((tmp, multiply(tX_test.T[17], degree=2)[0]))\n",
    "tmp = np.vstack((tmp, multiply(tX_test.T[19], degree=2)[0]))\n",
    "tmp = np.vstack((tmp, multiply(tX_test.T[24], degree=2)[0]))\n",
    "tmp = np.vstack((tmp, multiply(tX_test.T[25], degree=2)[0]))\n",
    "tmp = np.vstack((tmp, multiply(tX_test.T[27], degree=2)[0]))\n",
    "#cube: x: 0, 2, 4, 11,12,14,15,17,24,25,27,28\n",
    "tmp = np.vstack((tmp, multiply(tX_test.T[0], degree=3)[0]))\n",
    "tmp = np.vstack((tmp, multiply(tX_test.T[2], degree=3)[0]))\n",
    "tmp = np.vstack((tmp, multiply(tX_test.T[4], degree=3)[0]))\n",
    "tmp = np.vstack((tmp, multiply(tX_test.T[11], degree=3)[0]))\n",
    "tmp = np.vstack((tmp, multiply(tX_test.T[12], degree=3)[0]))\n",
    "tmp = np.vstack((tmp, multiply(tX_test.T[14], degree=3)[0]))\n",
    "tmp = np.vstack((tmp, multiply(tX_test.T[15], degree=3)[0]))\n",
    "tmp = np.vstack((tmp, multiply(tX_test.T[17], degree=3)[0]))\n",
    "tmp = np.vstack((tmp, multiply(tX_test.T[24], degree=3)[0]))\n",
    "tmp = np.vstack((tmp, multiply(tX_test.T[25], degree=3)[0]))\n",
    "tmp = np.vstack((tmp, multiply(tX_test.T[27], degree=3)[0]))\n",
    "tmp = np.vstack((tmp, multiply(tX_test.T[28], degree=3)[0]))\n",
    "#racine: x: 0, 1, 2, 3, 6, 7,8 , 9, 10, 13, 14,16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29\n",
    "tmp = np.vstack((tmp, sqrt_def(tX_test.T[0])[0]))\n",
    "tmp = np.vstack((tmp, sqrt_def(tX_test.T[1])[0]))\n",
    "tmp = np.vstack((tmp, sqrt_def(tX_test.T[2])[0]))\n",
    "tmp = np.vstack((tmp, sqrt_def(tX_test.T[3])[0]))\n",
    "tmp = np.vstack((tmp, sqrt_def(tX_test.T[6])[0]))\n",
    "tmp = np.vstack((tmp, sqrt_def(tX_test.T[7])[0]))\n",
    "tmp = np.vstack((tmp, sqrt_def(tX_test.T[8])[0]))\n",
    "tmp = np.vstack((tmp, sqrt_def(tX_test.T[9])[0]))\n",
    "tmp = np.vstack((tmp, sqrt_def(tX_test.T[10])[0]))\n",
    "tmp = np.vstack((tmp, sqrt_def(tX_test.T[13])[0]))\n",
    "tmp = np.vstack((tmp, sqrt_def(tX_test.T[14])[0]))\n",
    "tmp = np.vstack((tmp, sqrt_def(tX_test.T[16])[0]))\n",
    "tmp = np.vstack((tmp, sqrt_def(tX_test.T[17])[0]))\n",
    "tmp = np.vstack((tmp, sqrt_def(tX_test.T[18])[0]))\n",
    "tmp = np.vstack((tmp, sqrt_def(tX_test.T[20])[0]))\n",
    "tmp = np.vstack((tmp, sqrt_def(tX_test.T[21])[0]))\n",
    "tmp = np.vstack((tmp, sqrt_def(tX_test.T[22])[0]))\n",
    "tmp = np.vstack((tmp, sqrt_def(tX_test.T[23])[0]))\n",
    "tmp = np.vstack((tmp, sqrt_def(tX_test.T[24])[0]))\n",
    "tmp = np.vstack((tmp, sqrt_def(tX_test.T[25])[0]))\n",
    "tmp = np.vstack((tmp, sqrt_def(tX_test.T[26])[0]))\n",
    "print(tmp.shape)\n",
    "tmp = np.vstack((tmp, sqrt_def(tX_test.T[27])[0]))\n",
    "tmp = np.vstack((tmp, sqrt_def(tX_test.T[28])[0]))\n",
    "tmp = np.vstack((tmp, sqrt_def(tX_test.T[29])[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 568308)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tX_test = tmp.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30, 568308)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tX_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -3.05900328e+03,   2.01024145e+02,  -4.47733709e+02,\n",
       "         1.46072273e+01,  -6.38823959e+04,   3.61411414e-01,\n",
       "        -6.44159957e+01,   2.23992558e+06,   8.75772225e+01,\n",
       "        -1.34087314e+04,  -2.22382219e+04,   2.24329105e+05,\n",
       "        -4.70943254e+06,   1.35523884e+04,  -6.46829784e+06,\n",
       "         7.36596369e+02,   1.34197377e+04,   2.67653101e+07,\n",
       "        -1.08111081e+04,   1.59348637e+01,   2.16894891e+01,\n",
       "        -3.76181693e+00,  -2.99818975e+06,  -2.61316697e+00,\n",
       "         4.78776514e+06,  -7.33655155e+06,   7.91823830e+00,\n",
       "        -1.64000309e+07,  -5.79162851e+05,   1.34323858e+04,\n",
       "        -4.19609048e+01,   9.33791213e+03,  -1.82268194e+04,\n",
       "         1.37466237e+03,   2.51935622e+00,  -9.93393695e+01,\n",
       "        -5.04124655e+00,   1.82917237e+03,  -3.79544591e+03,\n",
       "         1.65570300e+02,  -4.20832786e-01,   6.12939715e+00,\n",
       "         1.51560056e+07,  -1.20592776e+09,  -2.88324522e+01,\n",
       "         9.33353416e+03,  -5.78211120e+05,   7.69242708e-01,\n",
       "        -3.37466389e+01,  -8.33854163e-01,   1.27093740e+01,\n",
       "        -8.44952150e+01,   5.54703926e+03,  -6.22422643e+07,\n",
       "         5.75246451e+09,   1.25989598e+09,  -1.12288819e+11,\n",
       "         5.77348602e+00,  -1.16962798e+02,  -6.97058118e+03,\n",
       "         3.29087425e+08,  -1.32842351e+10,   7.86196226e+05,\n",
       "        -1.93880400e+05,   1.69826507e+07,   1.04106882e+00,\n",
       "        -1.95676304e+01,   3.11893378e+04,  -1.27210868e+09,\n",
       "         4.81605541e+10,  -3.37707023e+06,  -3.90270066e+01,\n",
       "         2.60069123e+03,  -2.22393240e-01,  -1.51768960e+02,\n",
       "        -2.63687994e+00,   5.03356295e-01,  -3.59956653e+00,\n",
       "        -1.20150422e+04,   7.59179874e+05,   1.06451722e+00,\n",
       "         6.46967406e+03,  -1.92072797e+08,   6.05077738e+09,\n",
       "        -6.52470699e+05,  -8.40379919e+03,   3.53732472e+08,\n",
       "        -1.35645336e+10,   9.18171925e+05,   6.49473107e-01,\n",
       "        -8.56292814e+00,  -1.87792709e+04,   7.90334830e+08,\n",
       "        -3.01954317e+10,   2.05199594e+06,  -1.37324966e+03,\n",
       "         1.00139322e+09,   1.10601222e+05,   1.93664395e+00,\n",
       "        -3.55685915e+01])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "shapes (30,568308) and (100,) not aligned: 568308 (dim 1) != 100 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-1bf9b5853112>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mOUTPUT_PATH\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'csv/sample-submission.csv'\u001b[0m \u001b[0;31m# TODO: fill in desired name of output file for submission\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mcreate_csv_submission\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mids_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOUTPUT_PATH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/JulieDjeffal/Documents/EPFL/pattern/2016/ML_project1/projects/project1/scripts/Methods/proj1_helpers.py\u001b[0m in \u001b[0;36mpredict_labels\u001b[0;34m(weights, data)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mpredict_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;34m\"\"\"Generates class predictions given weights, and a test data matrix\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m     \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m     \u001b[0my_pred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0my_pred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: shapes (30,568308) and (100,) not aligned: 568308 (dim 1) != 100 (dim 0)"
     ]
    }
   ],
   "source": [
    "OUTPUT_PATH = 'csv/sample-submission.csv' # TODO: fill in desired name of output file for submission\n",
    "y_pred = predict_labels(weights, tX_test)\n",
    "print(y_pred)\n",
    "create_csv_submission(ids_test, y_pred, OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
